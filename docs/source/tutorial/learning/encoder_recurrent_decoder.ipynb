{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Recurrent Network Models for Human Dynamics\n",
    "\n",
    "Encoder-Recurrent-Decoder (ERD) is a model for prediction of human body poses from motion capture. The ERD model is a recurrent neural network that incorporates nonlinear encoder and decoder networks before and after recurrent layers.\n",
    "\n",
    "<div>\n",
    "<img src=\"../../../images/erd.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "[original image link](https://arxiv.org/pdf/2110.06901.pdf)\n",
    "\n",
    "An RNN captures motion dynamics in a latent space. The encoder and decoder feedforward DNNs map skeletal poses to this latent representation and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithm', 'dataset', 'render', '__init__.py', '__pycache__']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../../../../genmotion/\")\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt: {'exp_mode': 'train', 'learning_rate': 0.0001, 'input_dim': 62, 'output_dim': 62, 'position_loss_weight': 0.1, 'rotation_loss_weight': 1.0, 'model_save_path': 'e:\\\\researches\\\\GenMotion\\\\genmotion\\\\pretrained_models', 'frame_interval': 10, 'input_motion_length': 50}\n"
     ]
    }
   ],
   "source": [
    "from algorithm.encoder_recurrent_decoder.params import HDM05Params\n",
    "\n",
    "opt = vars(HDM05Params())\n",
    "print(\"opt:\",opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [00:00<00:02,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading amc files:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 456.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset.hdm05.hdm05_data_utils import HDM05Dataset\n",
    "\n",
    "data_path = \"E:/researches/GenMotion/dataset/HDM05/HDM_01-01_amc\"\n",
    "dataset = HDM05Dataset(data_path, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.encoder_recurrent_decoder.models import EncoderRecurrentDecoder\n",
    "\n",
    "model = EncoderRecurrentDecoder(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path your want to save the model\n",
    "# save_path = os.path.join(genmotion.__path__, \"../pretrained\")\n",
    "save_path = os.path.join(os.getcwd(), \"/../../pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.encoder_recurrent_decoder.trainer import HDM05Trainer\n",
    "\n",
    "trainer = HDM05Trainer(dataset, model, opt, device)\n",
    "\n",
    "print(\"training dataset size: \", len(trainer.train_dataset))\n",
    "print(\"evaluation dataset size: \", len(trainer.test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(epoch = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample encoder_recurrent_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.encoder_recurrent_decoder.sampler import HDM05Sampler\n",
    "from algorithm.encoder_recurrent_decoder.params import HDM05Params\n",
    "from dataset.hdm05.hdm05_data_utils import HDM05Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"E:/researches/GenMotion/dataset/HDM05/HDM_01-01_amc\"\n",
    "dataset = HDM05Dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = vars(HDM05Params(mode=\"sample\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genmotion\n",
    "save_path = os.path.join(genmotion.__path__[0], \"../pretrained/best.pth\")\n",
    "# save_path = os.path.join(os.getcwd(), \"/../pretrained\")\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = HDM05Sampler(save_path, opt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_motion = dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.sample(input_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be1319e0e5f68e9995c6387a47576bb513b1b8a8d0c4fb228c987c15c4df3d92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
